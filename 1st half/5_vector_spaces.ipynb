{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEcI5jfa32Wa"
   },
   "source": [
    "## Loading libraries aind downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d-c4dYjO0GKE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pAd1jYPkE0j"
   },
   "source": [
    "### Warm-up Exercise with Matrices\n",
    "\n",
    "Each of a set of $m$ patients can exhibit any number of $n$ possible symptoms.  \n",
    "We represent this as an $m \\times n$ matrix $S$, where  \n",
    "$S_{ij} = 1$ if the $i$-th patient exhibits symptom $j$, and $S_{ij} = 0$ otherwise.\n",
    "\n",
    "Write simple English explanations for the following matrix expressions:\n",
    "\n",
    "1. $S \\boldsymbol{1}$  \n",
    "2. $S^T \\boldsymbol{1}$  \n",
    "3. $S^T S$  \n",
    "4. $S S^T$  \n",
    "\n",
    "For example: $S \\mathbf{1}$ is an $m$-vector whose $i$-th element is ... that patient $i$ has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2bNyECUmNia"
   },
   "outputs": [],
   "source": [
    "\n",
    "#1\n",
    "print(\"S@1 is an m-vektor whose i-th element is amount of symptoms that patient i has\")\n",
    "#2\n",
    "print(\"S.T@1 is an n-vektor whose i-th element is amount of pacients that have i symptom\")\n",
    "#3\n",
    "print(\"pocet pacientov kotry maju tieto dva symptomps naraz\")\n",
    "#4\n",
    "print(\"pocet symptomov ktory maju tieto dva sympt naraz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErYgo0DM-dK5"
   },
   "source": [
    "## Vector Spaces, Bases, and Orthogonal Projections\n",
    "\n",
    "Determine whether the vectors $\\boldsymbol{a}_1$, $\\boldsymbol{a}_2$, and $\\boldsymbol{a}_3$ defined below:\n",
    "\n",
    "- form a **basis**, and  \n",
    "- are **orthogonal**.\n",
    "\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "px9VRJNM-aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. -0.]\n",
      " [ 0. -0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([0,0,-1])\n",
    "a2 = np.array([1,1,0])/(2)**0.5\n",
    "a3 = np.array([1,-1,0])/(2)**0.5\n",
    "\n",
    "A = np.vstack((a1,a2,a3)).T\n",
    "\n",
    "print(np.round(A.T @ A,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-l7050EJOMI"
   },
   "source": [
    "Given a vector $\\boldsymbol{b}_1 = (4, 2)^\\top$, find the projection $\\boldsymbol{b}_p$ of $\\boldsymbol{b}_2 = (1, 5)^\\top$ that is **orthogonal** to $\\boldsymbol{b}_1$.  \n",
    "Verify your calculation by checking that the resulting vector is indeed orthogonal to $\\boldsymbol{b}_1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lW3qVQ2uJOxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8]\n",
      " [1.4]]\n",
      "[[8.8817842e-16]]\n"
     ]
    }
   ],
   "source": [
    "b2 = np.array([[1],[5]])\n",
    "b1 = np.array([[4],[2]])\n",
    "\n",
    "bp = ((b2.T @ b1)/(b1.T @ b1)) * b1\n",
    "print(bp)\n",
    "print((b2 - bp).T @bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxV94CMF0HXV"
   },
   "source": [
    "Perform an **orthogonal projection** of the vector $\\boldsymbol{v} = (1, 2, 3, 4)^\\top$ onto the plane spanned by  \n",
    "$\\boldsymbol{u}_1 = (1, 6, 2, 2)^\\top$ and $\\boldsymbol{u}_2 = (2, -1, -1, 3)^\\top$.  \n",
    "\n",
    "Refer to the lecture slides for the equations needed to perform these calculations.\n",
    "\n",
    "**Hint:**  \n",
    "First, check whether $\\boldsymbol{u}_1$ and $\\boldsymbol{u}_2$ are orthogonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AglBFdQy0Hz6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[[1.8]\n",
      " [3. ]\n",
      " [0.6]\n",
      " [3. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=np.array([[1,2,3,4]]).T\n",
    "u1=np.array([[1,6,2,2]]).T\n",
    "u2=np.array([[2,-1,-1,3]]).T\n",
    "\n",
    "print(u1.T @ u2)\n",
    "\n",
    "w = (u1.T @ v) / (u1.T @u1)*u1 + (u2.T @ v) / (u2.T @ u2)*u2\n",
    "print(w)\n",
    "np.round((v-w).T @ u1,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXTNvtWToMvO"
   },
   "source": [
    "Perform an **orthogonal projection** of the vector  \n",
    "$\\boldsymbol{v} = (1, 2, 3, 4)^\\top$ onto the plane spanned by  \n",
    "$\\boldsymbol{u}_3 = (1, 1, 2, 3)^\\top$ and $\\boldsymbol{u}_4 = (2, 0, 1, 1)^\\top$.\n",
    "\n",
    "Refer to the lecture slides for the procedure to compute the projection.  \n",
    "Try to solve it using a **set of equations**, as demonstrated in the slides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xUQS4EpqtZ-4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 0]\n",
      " [2 1]\n",
      " [3 1]]\n",
      "[[15  7]\n",
      " [ 7  6]]\n",
      "[[21]\n",
      " [ 9]]\n",
      "[[ 1.53658537]\n",
      " [-0.29268293]]\n",
      "[[0.95121951]\n",
      " [1.53658537]\n",
      " [2.7804878 ]\n",
      " [4.31707317]]\n"
     ]
    }
   ],
   "source": [
    "v=np.array([[1,2,3,4]]).T\n",
    "u3=np.array([[1,1,2,3]]).T\n",
    "u4=np.array([[2,0,1,1]]).T\n",
    "# a little help\n",
    "U = np.hstack((u3,u4))\n",
    "print(U)\n",
    "G = U.T @ U\n",
    "print(G)\n",
    "b = U.T @ v\n",
    "print(b)\n",
    "c = np.linalg.inv(G) @ b\n",
    "print(c)\n",
    "w = U @ c\n",
    "print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXg9Mk91xDsN"
   },
   "source": [
    "## Gram–Schmidt Orthogonalization\n",
    "\n",
    "The **Gram–Schmidt algorithm** produces a set of **orthonormal vectors** from a collection of linearly independent vectors.  \n",
    "If some of the input vectors are linearly dependent, the algorithm detects this and stops.\n",
    "\n",
    "Given a set of vectors $\\boldsymbol{a}_1, \\boldsymbol{a}_2, \\dots, \\boldsymbol{a}_k$, we first want to find a projection of $\\boldsymbol{a}_2$ that is **perpendicular** to $\\boldsymbol{a}_1$.  \n",
    "How can we find such a vector?\n",
    "\n",
    "Given $\\boldsymbol{a}_1 = (0, 3)^\\top$, find the **orthogonal projection** of $\\boldsymbol{a}_2 = (4, 2)^\\top$ onto $\\boldsymbol{a}_1$, and then **rescale** the resulting projection to have **unit length**.  \n",
    "In other words, perform a **single step of the Gram–Schmidt orthogonalization** process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "nKxvQ3Y11T1n"
   },
   "outputs": [],
   "source": [
    "a1 = np.array([[0, 3]]).T\n",
    "a2 = np.array([[4, 2]]).T\n",
    "\n",
    "a = ((a2.T @ a1)/(a1.T @ a1)) * a1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaTGWXQ81UlZ"
   },
   "source": [
    "From *VMLS* (p. 97), the **Gram–Schmidt orthogonalization** process is defined as follows:\n",
    "\n",
    "Given $n$-vectors $\\boldsymbol{a}_1, \\boldsymbol{a}_2, \\dots, \\boldsymbol{a}_k$:\n",
    "\n",
    "---\n",
    "\n",
    "For $i = 1, \\dots, k$:\n",
    "\n",
    "1. **Orthogonalization:**  \n",
    "   $\\tilde{\\boldsymbol{q}}_i = \\boldsymbol{a}_i - (\\boldsymbol{q}_1^\\top \\boldsymbol{a}_i)\\boldsymbol{q}_1 - \\cdots - (\\boldsymbol{q}_{i-1}^\\top \\boldsymbol{a}_i)\\boldsymbol{q}_{i-1}$\n",
    "\n",
    "2. **Test for linear dependence:**  \n",
    "   If $\\tilde{\\boldsymbol{q}}_i = \\boldsymbol{0}$, stop.\n",
    "\n",
    "3. **Normalization:**  \n",
    "   $\\boldsymbol{q}_i = \\tilde{\\boldsymbol{q}}_i / \\lVert \\tilde{\\boldsymbol{q}}_i \\rVert$\n",
    "\n",
    "---\n",
    "For $i = 1$, the orthogonalization step reduces to $\\tilde{\\boldsymbol{q}}_1 = \\boldsymbol{a}_1$.\n",
    "\n",
    "---\n",
    "**Task**\n",
    "\n",
    "Complete the function below that performs the Gram-Schmidt orthogonalization for a matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vbf8QJm352I"
   },
   "outputs": [],
   "source": [
    "def gram_schmidt_orto(A):\n",
    "    n, m = A.shape # get the shape of A\n",
    "    Q = np.empty((n, m), dtype = A.dtype) # initialize matrix Q\n",
    "    Q[:,0] = A[:,0] / np.linalg.norm(A[:,0])\n",
    "    for i in range(1,m):\n",
    "        for i in range(1,m):\n",
    "            Q[:,i] = A[:,i]\n",
    "        for j in range(0,i):\n",
    "            #Q[:,i] = Q[:,i] - (A[:,i].T @ Q[:,j])/(Q[:,j].T @ Q[:,j]) * Q[:,j]\n",
    "            Q[:,i] = Q[:,i] - (Q[:,j].T @ A[:,i]) * Q[:,j]\n",
    "        if np.linalg.norm(Q[:,i]) == 0:\n",
    "            raise Exception(\"Vektors are a linear combinatoin\")\n",
    "        Q[:,i] /= np.sqrt(Q[:,i].T @ Q[:,i])\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WfJPE7Dtg2b"
   },
   "source": [
    "Below find a matrix to text it, where it will consist of vectors with $\\pm0.5$ as elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "uP1hkmdPzLoO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5        -1.          0.24981529]\n",
      " [ 0.5         3.         -0.67257964]\n",
      " [-0.5        -1.          0.28824842]\n",
      " [ 0.5         3.         -0.63414651]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  4.        , -0.92239493],\n",
       "       [ 4.        , 20.        , -4.45824216],\n",
       "       [-0.92239493, -4.45824216,  1.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix to test the orthogonalization:\n",
    "A = np.array([[-1., -1., 1.], [1.,  3.,  3.], [-1., -1.,  5.], [1.,  3.,  7.]], dtype = np.float64)\n",
    "\n",
    "A_o = gram_schmidt_orto(A)\n",
    "print(A_o)\n",
    "\n",
    "A_o.T @ A_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx8K-Sj03Vab"
   },
   "source": [
    "Print an answer what will happen if one of the vectors can be defined as a linear combination of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQ1X-pDm3YQe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LONicEQDNjA3"
   },
   "source": [
    "To verify your procedure, you can print the resulting matrices and compare them with the result from `np.linalg.qr()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bboB9XaJ4yn5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2r73m8MX4u-h"
   },
   "source": [
    "### Ortogonalizing a basis\n",
    "\n",
    "Orthogonalize the vectors $\\boldsymbol{u}_3 = (1, 1, 2, 3)^\\top$ and  \n",
    "$\\boldsymbol{u}_4 = (2, 0, 1, 1)^\\top$ using the **Gram-Schmidt algorithm**, so that projecting $\\boldsymbol{v} = (1, 2, 3, 4)^\\top$ onto the resulting orthogonal basis can be done **without computing a matrix inverse**.\n",
    "\n",
    "Start by generalizing the following code to work with matrices:\n",
    "```\n",
    "w = (u3.T @ v)/(u3.T @ u3)*u3 + (u4.T @ v)/(u4.T @ u4) * u4\n",
    "```\n",
    "To extract diagonal from a matrix as a vector, you can use `np.diag`.\n",
    "You may also notice, that there are dot products of ortonormal vectors, which can be simplified as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg546fPRAD5f"
   },
   "outputs": [],
   "source": [
    "v=np.array([[1,2,3,4]]).T\n",
    "u3=np.array([[1,1,2,3]]).T\n",
    "u4=np.array([[2,0,1,1]]).T\n",
    "# a little help\n",
    "U = np.hstack((u3, u4))\n",
    "\n",
    "U_o = gram_schmidt_orto(U)\n",
    "\n",
    "w = np.sum((U_o.T @ v).T * U_o, axis = 1).reshape(-1,1)\n",
    "(w - v).T @ U_o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX12OG2h6A0W"
   },
   "source": [
    "## Housing Stock\n",
    "\n",
    "In this section, we will estimate housing prices using the [Real Estate dataset](https://www.kaggle.com/datasets/quantbruce/real-estate-price-prediction?resource=download) from Kaggle.  \n",
    "The dataset will be downloaded by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "H4fnMhNgksyA"
   },
   "outputs": [],
   "source": [
    "real_estate_df = pd.read_csv(\"https://drive.google.com/uc?id=1lZMjd7v2sbtI91i_In5cm4-5LhX4e1IW\", header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoWPtMjxlCns"
   },
   "source": [
    "Now, we will perform an **orthogonal projection** of the vector `Y house price of unit area` onto the subspace spanned by the remaining features (the other columns of `real_estate_df`).\n",
    "\n",
    "Your task is to extract these remaining features into a NumPy array `X`, which will store vectors of the subspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "p0drFyAolCAA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0129170e+03 3.2000000e+01 8.4878820e+01 ... 2.4982980e+01\n",
      "  1.2154024e+02 1.0000000e+00]\n",
      " [2.0129170e+03 1.9500000e+01 3.0659470e+02 ... 2.4980340e+01\n",
      "  1.2153951e+02 1.0000000e+00]\n",
      " [2.0135830e+03 1.3300000e+01 5.6198450e+02 ... 2.4987460e+01\n",
      "  1.2154391e+02 1.0000000e+00]\n",
      " ...\n",
      " [2.0132500e+03 1.8800000e+01 3.9096960e+02 ... 2.4979230e+01\n",
      "  1.2153986e+02 1.0000000e+00]\n",
      " [2.0130000e+03 8.1000000e+00 1.0481010e+02 ... 2.4966740e+01\n",
      "  1.2154067e+02 1.0000000e+00]\n",
      " [2.0135000e+03 6.5000000e+00 9.0456060e+01 ... 2.4974330e+01\n",
      "  1.2154310e+02 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "y = real_estate_df.iloc[:,6].to_numpy()\n",
    "X = real_estate_df.iloc[:,:6].to_numpy() # extract the rest of columns (just change the subsetting sequence for column written above)\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1)))) # append column of ones\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4UIuCVWlTPl"
   },
   "source": [
    "Next, we will **orthogonalize** the columns of `X` to simplify the computation of matrix inverses and make the projection process more straightforward.  \n",
    "Orthogonalizing the columns ensures numerical stability and allows projections to be computed more efficiently. Below, store the coefficients of the projection in vector `beta`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NvCkvPolTnf"
   },
   "outputs": [],
   "source": [
    "X_o = gram_schmidt_orto(X)\n",
    "beta = X_o.T @ y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13TN3p1DmhFZ"
   },
   "source": [
    "Now, we can use the `beta` coefficients to estimate the values of `y`.  \n",
    "Simply multiply the orthogonalized matrix `X_o` by the coefficient vector `beta` and assign the result to `y_est`.\n",
    "\n",
    "Next, visualize `y_est` versus `y` to evaluate how well the estimated values approximate the actual data.  \n",
    "The red dashed line represents the line of **perfect predictions**, where the estimated and true values are equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBmZvtH5mgW2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_est = # estimate y\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y, y_est, alpha=0.6, edgecolor='k')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', label='Perfect estimate')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Estimated values')\n",
    "plt.title('Actual vs Estimated Scatter Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KA_DkxFmSMZ"
   },
   "source": [
    "Finally, compute RMSE of your estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs2V-lm9mSgu"
   },
   "outputs": [],
   "source": [
    "error = y_est - y\n",
    "RMSE = 0\n",
    "print(f\"RMSE:{RMSE:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2slVYajPxMD9"
   },
   "source": [
    "In the exercise above, we performed a **linear regression**.  \n",
    "If we were to obtain new data, we could use the coefficients stored in `beta` to make new predictions.  \n",
    "However, the new data would still be expressed in the **original (non-orthogonal)** basis, while the regression coefficients correspond to the **orthogonalized** basis.\n",
    "\n",
    "Therefore, before making predictions, we would need to compute the **transformation matrix** that maps the original basis to the new orthogonalized one, and then use this transformation to correctly project the new data before applying the model. The computation of the transformation matrix will be performed in the next lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3oeTwZ4uqFf"
   },
   "source": [
    "## Matrix Kernel\n",
    "\n",
    "Now, we will examine the **null space** (also called the **kernel**) of a matrix.\n",
    "\n",
    "We define a matrix `A` and a vector `b`, which together represent a **system of linear equations**.  \n",
    "First, determine the **rank** of `A` and the **rank** of the augmented matrix `A|b`.  \n",
    "\n",
    "Based on these ranks:\n",
    "- How many solutions does the system have?  \n",
    "- What geometric object (e.g., point, line, plane) represents the set of solutions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLLyMh10MdFZ"
   },
   "outputs": [],
   "source": [
    "# Matrix and right hand side vector\n",
    "A = np.array([[1., 2., 3.],\n",
    "              [2., 4., 6.],\n",
    "              [1., 1., 1.]])\n",
    "b = np.array([3., 6., 4.])\n",
    "\n",
    "# ranks\n",
    "rank_A = np.linalg.matrix_rank(A)\n",
    "rank_Ab = np.linalg.matrix_rank(np.column_stack((A, b)))\n",
    "print(f\"rank(A) = {rank_A}, rank([A|b]) = {rank_Ab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pErZP7OYH0Wc"
   },
   "source": [
    "A particular solution to the system can be obtained using the **pseudoinverse**.  \n",
    "This solution is also the one with the **smallest norm** among all possible solutions.\n",
    "\n",
    "Next, use the `scipy.linalg` module to find the **null space** of the matrix.  \n",
    "The resulting basis vector `ns_A` of the null space is of **unit length** and forms a basis for a **one-dimensional subspace** of $\\mathbb{R}^3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOmwgM_wIKgM"
   },
   "outputs": [],
   "source": [
    "# Pseudoinverse\n",
    "x_p = np.linalg.pinv(A) @ b\n",
    "print(\"Particular solution x_p:\")\n",
    "print(x_p)\n",
    "print(\"Verify that A @ x_p ~ b:\", np.allclose(A @ x_p, b))\n",
    "\n",
    "# null_space computation\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "ns_A = null_space(A)\n",
    "print(\"Basis of nullspace ker(A) (columns):\")\n",
    "print(ns_A)\n",
    "print(\"Verification A @ n ~ 0:\", np.allclose(A @ ns_A, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlm3ZmeZHECk"
   },
   "source": [
    "Next, we will find a **solution vector** and a **vector belonging to the kernel** whose elements are **integers**, making the results easier to read and interpret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSotvaq3PcQe"
   },
   "outputs": [],
   "source": [
    "ns_A = null_space(A)\n",
    "nice_null_space = 1/ns_A[0]*ns_A\n",
    "print(f\"null space vector:\\n\",nice_null_space)\n",
    "# this can be found by Gauss-Jordan elimination :)\n",
    "x_nice = np.array([5,-1,0]).reshape(-1,1)\n",
    "print(f\"solution vector:\\n\", x_nice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEHeluGQsypA"
   },
   "outputs": [],
   "source": [
    "np.round(np.linalg.pinv(A),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpa4gJoKaveK"
   },
   "source": [
    "Now, we can verify that adding any vector from the **null space** of $A$ to a particular solution still yields a valid solution to the system of equations:\n",
    "\n",
    "$$A(\\boldsymbol{x} + \\boldsymbol{v}) = \\boldsymbol{b}, \\quad \\boldsymbol{v} \\in \\ker(A).\n",
    "$$\n",
    "\n",
    "Write this equation in Python and experiment with different values of the scalar $t$,  \n",
    "which you can use to generate new solution vectors of the form:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_{\\text{new}} = \\boldsymbol{x} + t \\boldsymbol{v}, \\quad \\text{where } \\boldsymbol{v} \\in \\ker(A).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PQ6DL55MnVm"
   },
   "outputs": [],
   "source": [
    "t = -5\n",
    "# write the equation above"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNf+UHHPqRkMhvpZlE3sVap",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
